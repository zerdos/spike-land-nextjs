---
title: "The Testing Pyramid Is Upside Down"
slug: "the-testing-pyramid-is-upside-down"
description: "What if the worst part of your test suite — the slow, flaky E2E tests — could run at unit test speed? MCPs might be the answer nobody expected."
date: "2026-02-13"
author: "Zoltan Erdos"
category: "Developer Experience"
tags: ["testing", "mcp", "unit-testing", "e2e", "architecture", "agents"]
featured: true
---

*Dedicated to the memory of László Merklik (1975–2018), who left us far too soon. He was in his early forties when cancer took him. As co-founder and CPO of Emarsys — later acquired by SAP — he built one of Hungary's most respected engineering cultures. He even gave a talk called "Better Quality Without Testers," which feels like a direct ancestor of the ideas in this article.*

*László was the person who made me care about coding. Not just doing it — caring about it. He taught me that there is a special relationship between a unit test and the code it tests: when both are written properly, one specifies the other. The test tells you what the code should do. The code tells you what the test should verify. They are two views of the same truth.*

*He was the kind of developer who made everyone around him better. The kind who would stay after the talks to help a junior fix their build. The kind who believed that writing software well was a form of respect — for your teammates, for your users, for yourself. This article is about pushing the craft forward. That was his thing too.*

---

## The Conference

About fifteen years ago, I went to a developer conference in Budapest. The topic was Jasmine — which ran in the browser, since Node.js itself wasn't widely adopted yet. This was before Jest had eaten the world, before testing was a given on every project. Testing was still something you had to argue for.

The presenter was young. Nervous energy. He had clearly been converted recently — you could see it in his eyes. He walked us through how a few dozen unit tests had caught a regression that would have shipped to production. He showed how mocking worked. He showed how fast the feedback loop was. He was practically vibrating.

Then someone in the audience raised their hand.

"Es hogy teszteljük le az UI-t?" the person asked — *"And how do we test the UI?"*

The presenter paused. Then he shrugged.

"Az UI-t? Azt teszteljék a hülyék!" — *"The UI? Let the idiots test that!"*

A few people laughed. Most nodded. It seemed reasonable at the time. The unit tests covered the business logic. The UI was just HTML and CSS. You look at it, it either looks right or it does not. What is there to automate?

That answer stayed with me for a long time. Not because it was wrong. Because it was almost right — and the gap between almost right and actually right would cost our industry a decade of pain.

---

## What Happened Next

We did start testing UI. Of course we did.

First came Selenium. Then Protractor. Then Cypress. Then Playwright. Each one better than the last. Each one promising to finally make browser testing reliable.

And they did get better. Playwright in particular is a genuinely excellent tool. But the fundamental problem never went away: you are controlling a real browser, rendering real DOM, waiting for real network requests, and hoping that the timing works out. You are testing through the thickest, most unpredictable layer of your entire stack.

These tests became the worst part of every test suite I have ever worked on.

They are slow. A fast unit test suite runs in seconds. A comprehensive E2E suite runs in minutes — sometimes tens of minutes. On CI, with parallelization and retries, you are looking at pipeline times that make developers context-switch to something else while they wait.

They are flaky. Not because the tools are bad, but because browsers are complex state machines. A test that passes locally fails on CI because the animation took 50ms longer. A test that ran fine yesterday fails today because a third-party script loaded slower. You add `waitForSelector`. You add `waitForTimeout`. You add retry logic. You are not testing your application anymore — you are testing your ability to synchronize with chaos.

They are brittle. Change a CSS class? Tests break. Move a button from the left sidebar to the top nav? Tests break. Refactor a component that behaves identically but renders differently? Tests break. The tests are coupled to the implementation in exactly the way we tell junior developers not to write unit tests.

This is the testing pyramid. Unit tests at the base: fast, cheap, many. Integration tests in the middle: moderate speed, moderate cost, moderate count. E2E tests at the top: slow, expensive, few.

Everyone knows the top of the pyramid is painful. We accepted it as the cost of doing business. You need *some* E2E tests because that is the only way to verify the full user flow. API tests are not enough — they test endpoints, not the business logic flows that string those endpoints together into something a user actually does.

Or so we thought.

---

## The Insight

Here is the thing about E2E tests that nobody talks about clearly enough: most of them are not really testing the browser. They are testing business logic *through* the browser.

Think about what a typical E2E test actually verifies. "User logs in, navigates to settings, changes their email, confirms the change, sees the updated email on the profile page." What are you really testing here? You are testing that the email change flow works. The login, the navigation, the form submission, the confirmation, the state update — that is all business logic. The browser is just the delivery mechanism.

This is where MCPs change everything.

MCP — Model Context Protocol — is a standard for exposing your application's capabilities as structured tools. Text in, text out. An agent sends a request describing what it wants to do, your MCP server executes the action and returns the result. No browser. No DOM. No CSS selectors. No timing issues.

If you write your user stories as MCP tools, you have created a testable contract for your business logic.

Let me show you what I mean.

Say you have a user story: "A user can update their email address." In the E2E world, the test looks something like this:

```typescript
// Cypress E2E test
describe('Email update flow', () => {
  it('should allow user to change their email', () => {
    cy.login('test@example.com', 'password123');
    cy.visit('/settings');
    cy.get('[data-testid="email-input"]').clear().type('new@example.com');
    cy.get('[data-testid="save-button"]').click();
    cy.get('[data-testid="confirm-dialog"]').should('be.visible');
    cy.get('[data-testid="confirm-button"]').click();
    cy.get('[data-testid="success-toast"]').should('contain', 'Email updated');
    cy.visit('/profile');
    cy.get('[data-testid="user-email"]').should('contain', 'new@example.com');
  });
});
```

This test takes 5-15 seconds to run. It depends on CSS selectors, DOM structure, animation timing, and network latency. Change the confirm dialog to a modal? Test breaks. Move the success message from a toast to an inline alert? Test breaks.

Now here is the same business logic exposed as an MCP tool:

```typescript
// MCP tool definition
const updateEmailTool = {
  name: 'update_user_email',
  description: 'Update the authenticated user\'s email address',
  inputSchema: {
    type: 'object',
    properties: {
      newEmail: { type: 'string', format: 'email' },
      confirmChange: { type: 'boolean' },
    },
    required: ['newEmail', 'confirmChange'],
  },
  handler: async ({ newEmail, confirmChange }, context) => {
    const user = await context.getAuthenticatedUser();
    if (!user) return { error: 'Not authenticated' };

    if (!confirmChange) {
      return {
        status: 'confirmation_required',
        message: `Confirm email change from ${user.email} to ${newEmail}?`,
      };
    }

    await context.userService.updateEmail(user.id, newEmail);
    return {
      status: 'success',
      message: `Email updated to ${newEmail}`,
      updatedEmail: newEmail,
    };
  },
};
```

And the unit test:

```typescript
// Unit test for the MCP tool
describe('update_user_email', () => {
  it('should update email when confirmed', async () => {
    const context = createMockContext({
      user: { id: '1', email: 'old@example.com' },
    });

    const result = await updateEmailTool.handler(
      { newEmail: 'new@example.com', confirmChange: true },
      context,
    );

    expect(result.status).toBe('success');
    expect(result.updatedEmail).toBe('new@example.com');
    expect(context.userService.updateEmail).toHaveBeenCalledWith(
      '1',
      'new@example.com',
    );
  });

  it('should require confirmation before updating', async () => {
    const context = createMockContext({
      user: { id: '1', email: 'old@example.com' },
    });

    const result = await updateEmailTool.handler(
      { newEmail: 'new@example.com', confirmChange: false },
      context,
    );

    expect(result.status).toBe('confirmation_required');
    expect(context.userService.updateEmail).not.toHaveBeenCalled();
  });

  it('should reject unauthenticated requests', async () => {
    const context = createMockContext({ user: null });

    const result = await updateEmailTool.handler(
      { newEmail: 'new@example.com', confirmChange: true },
      context,
    );

    expect(result.error).toBe('Not authenticated');
  });
});
```

This test runs in milliseconds. It does not depend on any DOM structure. It does not care what the UI looks like. It tests the exact same business logic — the email update flow with confirmation — but at unit test speed, with unit test reliability.

You have not lost any coverage. You have lost the browser.

---

## The Architecture Argument

This is not just a testing trick. It is an architectural shift.

When you expose your user stories as MCP tools, you create a chain:

**User stories → MCP tools → Unit-testable business logic**

The same spec serves three purposes simultaneously:

1. **User documentation.** The MCP tool descriptions *are* your feature documentation. "Update the authenticated user's email address" — that is the spec, written in plain language, living in the code.

2. **Agent interface.** Any AI agent that connects via MCP can now execute your user stories. Your app is agent-ready not because you bolted on an AI feature, but because your business logic is accessible through a structured text interface.

3. **Test contract.** The input schema defines what the tool accepts. The handler defines the expected behavior. The response defines the expected output. That is a contract. You can test it the same way you test any function — because it *is* a function.

You are not adding test infrastructure. You are adding agent capability that *happens* to be testable. The testing is a side effect of good architecture.

This is the key insight that took me years to see: the reason E2E tests are painful is not that browser automation is hard (though it is). It is that we were forced to go through the browser because there was no other way to exercise full user flows. The browser was the only interface that connected all the pieces.

MCPs give you a second interface. A text-based one. One that connects the same pieces but without the rendering layer, without the timing issues, without the CSS selectors.

---

## The Third Player

László taught me the duality: a unit test and its code, when written properly, specify each other. Two players, one truth.

But I think there is a third player: the name.

Consider the MCP tool from earlier: `update_user_email`. That name is not just a label. It is a constraint. It tells you what the tool must do and what it must not do. It does not send notifications. It does not update the password. It updates the user's email. The name *is* the spec.

This is not a new idea — good naming has always mattered. But MCP makes it structural. The tool name is the address, and if the address is written properly, the building instructions are encoded in it. You do not need a separate document explaining what `update_user_email` does. The name, the input schema, and the handler form a triangle where each vertex constrains the other two.

Test. Code. Name. Three players, one truth.

We had the first two for decades. We just never formalized the third into something a machine could reason about. MCP does that. And it turns out, when you give the name enough structure to be machine-readable, it becomes machine-testable too.

---

## Practical Steps

If you are staring at a flaky E2E suite right now, here is how to start.

**Step 1: Find your most painful E2E tests.** You know which ones they are. The ones you re-run three times before they pass. The ones that have `// TODO: figure out why this is flaky` comments. The ones that take 30 seconds each.

**Step 2: Ask what business logic they actually verify.** Strip away the clicks and the waits and the selectors. What is the test really checking? "User can cancel their subscription." "Admin can ban a user." "Payment flow handles declined cards." That is the business logic.

**Step 3: Expose that logic as MCP tools.** Write an MCP tool for each business flow. Define the input schema, implement the handler using your existing services, return structured results. You are not rewriting anything — you are wrapping your existing business logic in a structured interface.

**Step 4: Write unit tests for the MCP tools.** Mock the dependencies. Test the happy path. Test the error cases. Test the edge cases. These tests will run in milliseconds and they will never flake.

**Step 5: Watch your E2E suite shrink.** You will still need some E2E tests — for visual regressions, for browser-specific behavior, for the final "does the page actually render" check. But the number will drop dramatically. The ones you keep will be simpler and more stable because they are not carrying the weight of business logic verification anymore.

You are not replacing E2E tests. You are moving the business logic out of them. What remains is a thin layer of visual smoke tests — which is all E2E tests should have been in the first place.

---

## The CI Dividend

Once your business logic lives in MCP tools, tightly coupled to your frontend through TypeScript, something remarkable happens to your CI pipeline.

Run this:

```bash
yarn vitest run --changed main
```

Vitest knows which files changed since `main`. It knows which tests import those files. It runs only those tests. A change to `update_user_email` runs the email tests, not the entire suite. This takes seconds, not minutes.

But the real trick is what comes next.

Your CI has coverage logs. It has git history. It knows which MCP tools changed, which unit tests cover them, and which E2E scenarios exercise those flows. An AI reviewer agent can read this graph and make a decision: which E2E tests actually need to run?

Updated the description in a test fixture file? No E2E tests needed. Changed the email validation logic in an MCP tool? Run the email-related E2E scenarios, skip the rest. Refactored a shared utility? The agent traces the dependency graph and runs exactly the affected tests — nothing more, nothing less.

This is incremental review, powered by the same coupling that made your unit tests fast. The MCP tool names give the agent enough semantic context to reason about blast radius. `update_user_email` changed? The agent knows to run the email E2E tests. `list_user_notifications` unchanged? Skip those.

The savings compound. On a large codebase, a typical PR touches a fraction of the business logic. Running the full E2E suite for every PR is like rebuilding the entire house because you changed a doorknob. With MCP-structured business logic and an AI reviewer, your CI runs only what matters.

Less compute. Faster feedback. Fewer flaky failures from tests that had nothing to do with your change. The testing pyramid does not just collapse — it gets smart.

---

## The Pyramid, Reconsidered

The testing pyramid was always a compromise. We put E2E tests at the top not because we wanted them to be slow and few, but because that was the constraint. Full user flow verification required a browser. Browsers are slow. Therefore, full user flow tests are slow. Therefore, write fewer of them.

MCPs break that constraint.

If your business logic is accessible through a text interface, full user flow verification does not require a browser. It requires a function call. Function calls are fast. Therefore, full user flow tests are fast. Therefore, write as many as you want.

The pyramid does not flip upside down. It collapses. The painful top layer — the E2E layer — gets thin. Almost everything that was in it moves down to the unit test layer. Not because you found a clever way to mock the browser, but because you removed the need for the browser entirely.

The remaining E2E tests do what they should have always done: verify that the page renders, that the buttons are clickable, that the visual design is correct. Pure UI concerns. "Let the idiots test that" — except now the "idiots" are Playwright running a handful of fast visual checks, not a hundred slow business logic simulations.

---

## Full Circle

I still think about that conference sometimes. The young presenter, vibrating with excitement about unit tests. The person in the audience asking about UI testing. The dismissive answer.

"Az UI-t? Azt teszteljék a hülyék!" — *"The UI? Let the idiots test that!"*

He was not wrong. He was early.

The real answer to the UI testing question was never "automate the browser." The real answer was: make the business logic accessible without one. We just did not have the interface for it yet.

Now we do.

László would have loved this. Not the technology itself — he was never the type to get excited about a protocol or a spec. He would have loved what it means for the craft. Less time fighting flaky tests. More time building things that matter. More time helping the junior developer after the talks.

That is what pushing the craft forward looks like. Not flashy new tools. Quieter feedback loops. Less friction between intent and verification. The boring kind of progress that makes everything else possible.

I think about him every time I delete a flaky test. I think he would approve.
