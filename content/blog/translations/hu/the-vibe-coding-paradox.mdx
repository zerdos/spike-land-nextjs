---
title: "A Vibe Coding Paradoxon: Miért Lesz Butább az AI-d, Minél Több Szabadságot Adsz Neki"
slug: "the-vibe-coding-paradox"
description: "Építettünk egy AI-t, ami React appokat generál URL-ekből. Az esetek 40%-ában működött. Aztán megtanítottuk, hogy tanuljon a saját hibáiból -- ugyanazt a fizikát használva, ami miatt a promptjaid kudarcot vallanak."
date: "2026-02-12"
author: "Zoltan Erdos"
category: "Fejlesztői Élmény"
tags: ["ai", "context-engineering", "claude", "agents", "önjavító", "developer-tools", "vibe-coding", "fizika"]
featured: true
language: "hu"
---

{/* TL;DR Box */}
<div className="bg-slate-800/50 border border-slate-700 rounded-lg p-6 mb-8">
  <h3 className="text-lg font-semibold mb-3 text-slate-200">TL;DR</h3>
  <ul className="space-y-2 text-slate-300">
    <li>A vibe codingnak fizikai problémája van: a figyelem nullaösszegű erőforrás, és a remélj-és-imádkozz generálás a nagyrésztét elpazarolja.</li>
    <li>A spike.land app létrehozójának sikerarátát 40%-ról önjavító ágensre alakítottuk, ami minden kudarcból tanul.</li>
    <li>A javítás pontosan a termodinamikára képezhető: őrizd meg az energiát (stabil prompt prefixum), vezesd el a hőt (tömörítsd a hibákat tanulási jegyzetekbe), és hagyd, hogy a természetes szelekció metsze a rossz tudást.</li>
    <li>3 Claude modell kaszkádolva költség szerint: Opus alkot ($$$), Sonnet debugol ($$), Haiku tanul ($).</li>
    <li>Maga a rendszer is a Claude Code terv módjával lett tervezve -- kontextus-tervezés végig lefelé.</li>
  </ul>
</div>

## A Paradoxon

Építettem egy AI-t, ami React appokat generál URL-ből.

Írd be a `/create/games/tetris` címet, kapsz egy játszható Tetrist. Írd be a `/create/finance/dashboard` címet, kapsz egy valós idejű részvény diagramot. Az URL a prompt. Az app másodpercek alatt megjelenik.

Varázslatosnak hangzik. Íme, mi történt valójában: az esetek 40%-ában működött.

<SplitScreenDemo />

A másik 60%? Törött importok. Nem definiált változók. Appok, amik betöltéskor kriptikus transpilációs hibákkal omlottak össze. Az AI elég okos volt, hogy megírja a Tetrist -- csak nem volt elég okos, hogy *emlékezzen* arra, hogy korábban már kudarcot vallott a Tetrisnél.

Minden generálás a nulláról indult. Nincs emléke a múltbeli kudarcoknak. Nincs feljegyzése arról, mely importok működnek és melyek adnak 404-et. Nincs felhalmozott bölcsesség. Csak nyers intelligencia, ami egy problémára irányul nulla intézményi tudással.

Íme a paradoxon, ami megtöri az intuíciót: az AI-nak **több szabadság** adása -- hagyni, hogy "vibe codoljon" -- **rosszabb eredményeket** hoz, mint a korlátozása. Azt gondolnád, kevesebb szabály több kreativitást jelent. A fizika mást mond.

A paradoxonnak neve van a szakterületen: **kontextus-tervezés.** És van egy fizikai mechanizmusa, ami pontosan megmagyarázza, miért vall kudarcot a vibe coding -- és pontosan hogyan javítsd ki.

Ez a háromrészes sorozat harmadik cikke. Az [első](/blog/context-engineering-your-zero-shot-prompt) bemutatta az 5 rétegű kontextus vermet -- egy keretrendszert ahhoz, hogy előre betölts mindent, amire az AI-nak szüksége van az első próbálkozásra való sikerhez. A [második](/blog/how-claude-code-engineers-context) bement a transformer belsejébe, hogy elmagyarázza, *miért* számít a kontextus a figyelem szintjén. Ez a cikk mindkettőt alkalmazza egy valós termékfunkció építésére: egy önjavító ágens, ami React appokat generál és tanul a saját hibáiból.

---

## A Fizikája Annak, Miért Vall Kudarcot a Vibe Coding

<AttentionSpotlightDemo />

Kezdjük az első elvekből. Mi az a token?

A token az LLM világának atomegysége. Minden karakter, amit beírsz, minden utasítás, amit adsz, minden kontextus, amit megadsz, tokenekre bomlik. Egy tipikus angol szó 1-2 token. Egy sor kód 10-15 lehet. A modell ezeket a tokeneket az **önfigyelem** nevű mechanizmuson keresztül dolgozza fel, és íme az egyenlet, ami irányítja:

```
attention = softmax(QK^T / sqrt(d)) x V
```

A döntő rész a `softmax`. Normalizálja a figyelmi súlyokat, hogy összegük 1,0 legyen. Ez egy megmaradási törvény, struktúrájában azonos a fizika energiamegmaradásával. Nem tudsz figyelmet teremteni a semmiből. Van egy rögzített költségvetés. A kontextusablak minden tokenje versenyez ennek a költségvetésnek egy részéért.

**A figyelem olyan, mint egy szoba egyetlen reflektorral.** A vibe coding 20 embert rak a szobába és reméli, hogy a reflektor megtalálja a megfelelőt. A kontextus-tervezés 3 embert rak a szobába és a reflektort a padlóhoz szegezi.

Amikor 10 000 token lényegtelen kontextust öntesz a promptba -- "minden eshetőségre" -- nem vagy alapos. Halványítod a reflektort. A releváns tokenek még ott vannak. Csak 9500 lényegtelen tokennel versenyeznek a modell véges figyelméért.

<Callout type="info">
**A fizika számszerűsítve van.** Egy 2025-ös tanulmány, amelynek címe "Context Length Alone Hurts LLM Performance Despite Perfect Retrieval", 47,6%-os pontosság-csökkenést talált 30K tokennél kódolási feladatoknál -- még akkor is, amikor a visszakeresés tökéletes volt és nem voltak eltérő tényezők. Még az üres szóközök is 7-48%-os teljesítményesést okoztak. Ez nem szoftver hiba. Ez fizika. Több token = több hígítás = rosszabb eredmények.
</Callout>

Ez magyarázza a paradoxont. A vibe coding -- "csak generálj valamit és meglátjuk" -- működik rövid, egyszerű promptokkal. De ahogy az összetettség nő, a struktúra hiánya azt jelenti, hogy a modell figyelme szétszóródik egy egyre növekvő kontextusban. A jel belefullad a zajba. Nem azért, mert a modell buta, hanem mert a softmax nullaösszegű játék.

---

## Az Előtte -- Egy Vibe Coder Anatómiája

Legyünk őszinték azzal kapcsolatban, honnan indultunk. Az eredeti app generátor egyszerű, tiszta és elégtelen volt.

Egyetlen Gemini API hívás. Egyetlen újrapróba kudarc esetén. Nincs memória. Nincs tanulás. Nincs strukturált hibakezelés. Íme a fallback útvonal, ami a *teljes* rendszerünk volt:

```typescript
// A régi mód: egyetlen lövés, reméld a legjobbat
async function* geminiFallbackStream(slug, path, userId) {
  const { content, rawCode, error } = await generateAppContent(path);

  let updateResult = await updateCodespace(codespaceId, codeToPush);

  if (!updateResult.success) {
    // Egyetlen újrapróba hiba javítással
    const correctedCode = await attemptCodeCorrection(
      codeToPush, updateResult.error, slug
    );
    if (correctedCode) {
      updateResult = await updateCodespace(codespaceId, correctedCode);
    }
  }

  if (!updateResult.success) {
    throw new Error(updateResult.error || "Failed to update codespace");
  }
}
```

Mint egy diák, aki tanulás nélkül írja a vizsgát: néha briliáns, általában közepes. És ami döntő -- egy diák, aki **mindent elfelejt** vizsgák között.

| | Előtte (Vibe Coding) | Utána (Kontextus-tervezett Ágens) |
|---|---|---|
| **Modell** | Gemini Flash (egyetlen hívás) | Claude Opus -> Sonnet -> Haiku (kaszkád) |
| **Újrapróbák** | 1 vak újrapróba | Akár 3 célzott javítás hiba-diagnózissal |
| **Memória** | Nincs | Bayesi tanulási jegyzetek, DB-ben tárolva |
| **Hibakezelés** | Nyers hiba string -> újrapróba | Strukturált elemzés -> kategorizált javító promptok |
| **Képességek** | Generikus prompt | 14 képesség definíció kulcsszavak szerint |
| **Prompt gyorsítótárazás** | Nincs | Osztott blokkos KV cache (10x költségmegtakarítás) |
| **Fallback** | Nincs | Ágens proxy -> Közvetlen Claude -> Gemini |

---

## A Kontextus Megmaradása -- Az 5 Rétegű Javítás

A helyzet a következő: a javítás nem több AI. Jobb fizika.

<FiveLayerStackDemo />

Az [5 rétegű kontextus verem](/blog/context-engineering-your-zero-shot-prompt) -- Identitás, Tudás, Példák, Korlátozások, Eszközök -- nem csak egy keretrendszer. Megmaradási stratégia. A rétegek, amik nem változnak, gyorsítótárazódnak (olcsók). A rétegek, amik változnak, hozzáfűződnek (frissek). A modell figyelmi költségvetése a megfelelő dolgokra fordítódik, mert a prompt úgy van strukturálva, hogy ez megtörténjen.

Íme, hogyan képezhető le kódra:

| Keretrendszer Réteg | Fizikai Analógia | Kód Implementáció |
|---|---|---|
| **Identitás** (1. réteg) | Megmaradási törvény -- stabil vonatkoztatási keret | `AGENT_IDENTITY` -- gyorsítótárazott, soha nem változik |
| **Tudás** (2. réteg) | Friss mérés -- dinamikus kísérletenként | Tanulási jegyzetek -- újraépítve kérésenként |
| **Példák** (3. réteg) | Kalibrációs adatok -- stabil műszerbeállítások | Képesség promptok -- kategóriánként gyorsítótárazott |
| **Korlátozások** (4. réteg) | Határfeltételek -- beállításonként rögzített | Kimeneti specifikáció, javítási szabályok -- gyorsítótárazott |
| **Eszközök** (5. réteg) | Mérési apparátus -- definiálja, mi megfigyelhető | Transpiler, codespace API -- implicit |

A kulcsfüggvény a `buildAgentSystemPrompt`. *Osztott blokkokat* ad vissza -- egy stabil prefixumot a gyorsítótárazáshoz és egy dinamikus szuffixumot a frissességhez:

```typescript
export function buildAgentSystemPrompt(
  topic: string,
  notes: LearningNote[],
): SplitPrompt {
  // Stabil prefixum: identitás + alapvető képességek + kimeneti spec -> gyorsítótárazott
  const coreWithSkills = buildSkillSystemPrompt(topic);
  const stablePrefix = `${AGENT_IDENTITY}\n\n${coreWithSkills}\n\n${OUTPUT_SPEC}`;

  // Dinamikus szuffixum: tanulási jegyzetek -> NEM gyorsítótárazott, változik kérésenként
  const noteBlock = formatNotes(notes);

  return {
    stablePrefix,
    dynamicSuffix: noteBlock,
    full: noteBlock ? `${stablePrefix}\n\n${noteBlock}` : stablePrefix,
  };
}
```

A stabil prefixum `cache_control: { type: "ephemeral" }` jelzést kap az API hívásban. Az ugyanazon témájú következő kéréseknél ezek a tokenek a KV cache-ből szolgáltatódnak **10x alacsonyabb költségen**. A dinamikus szuffixum -- a tanulási jegyzetek -- kérésenként változik és nem érvényteleníti a cache-t.

<Callout type="success">
**KV Cache Felismerés:** Az identitás, képességek és kimeneti specifikáció ~2000 token, ami soha nem változik az ugyanazon kategória generálásai közt. Gyorsítótárazásuk kérésenként $0,009-et takarít meg. Ezernyi generáció során ez a különbség egy költséghatékony szolgáltatás és egy pénznyelő közt. A kontextus-tervezés nem csak technikailag megalapozott -- gazdaságilag optimális.
</Callout>

Ez a kontextus megmaradása a gyakorlatban. A stabil vonatkoztatási keret (identitás + képességek + kimeneti spec) olyan, mint a fizika megmaradó mennyiségei -- energia, impulzus, töltés. Interakciókon át megmaradnak. A dinamikus megfigyelések (tanulási jegyzetek) olyanok, mint a kísérleti mérések -- minden alkalommal frissek, arra építve, amit a megmaradó keret lehetővé tesz.

---

## A Javítási Hurok -- Természetes Szelekció Kódnak

<DarwinianTreeDemo />

Az ágens hurok darwinista szelekció kódnak. Generál (mutáció) -> Transpilál (környezeti teszt) -> Javít (alkalmazkodás) -> Tanul (örökölhető emlékezet). Akár 3 iteráció -- 3 generáció evolúció kérésenként.

<AgentLoopDemo />

```typescript
export async function* agentGenerateApp(
  slug: string,
  path: string[],
  userId: string | undefined,
): AsyncGenerator<StreamEvent> {
  const maxIterations = Math.min(
    parseInt(process.env["AGENT_MAX_ITERATIONS"] || "3", 10),
    MAX_ITERATIONS_CAP,
  );
  // ...

  // === GENERÁLÁS: Claude Opus hívás ===
  const genResponse = await callClaude({
    systemPrompt: systemPrompt.full,
    stablePrefix: systemPrompt.stablePrefix,
    dynamicSuffix: systemPrompt.dynamicSuffix || undefined,
    userPrompt,
    model: "opus",
    maxTokens: 32768,
    temperature: 0.5,
  });
```

Az első hívás **Opus**-t használ **0.5** hőmérsékleten -- kreatív felfedezés. Magas hőmérséklet magas entrópiát jelent, véletlenszerűbb mintavétel a valószínűség-eloszlásból. Jó újszerű megoldások generálásához. Rossz pontos sebészethez.

Amikor a kód megbukik a transpiláláson, a javító modell **Sonnet**-re vált **0.2** hőmérsékleten -- pontos, determinisztikus, fókuszált:

```typescript
      // === JAVÍTÁS: Kérd meg a Claude Sonnet-et a hiba javítására ===
      const fixResponse = await callClaude({
        systemPrompt: fixSystemPrompt.full,
        stablePrefix: fixSystemPrompt.stablePrefix,
        dynamicSuffix: fixSystemPrompt.dynamicSuffix || undefined,
        userPrompt: fixUserPrompt,
        model: "sonnet",
        maxTokens: FIX_MAX_TOKENS,
        temperature: 0.2,
      });
```

De a lényeg... **a javító modell más modell, mint a generáló.** Ez olyan, mintha a korrektor nem a szerző lenne. Elkapják azokat a hibákat, amikre a szerző vak. A generáló (Opus) kreatív lendülettel rendelkezik -- befektetett az architekturális döntéseibe. A javító (Sonnet) csak a hibát és a kódot látja, a dizájnhoz kötött ego nélkül.

A hőmérséklet mint fizikai paraméter tisztán leképezhető: magasabb hőmérséklet = magasabb entrópia = a valószínűségi tér több feltérképezése. Alacsonyabb hőmérséklet = determinisztikusabb = valószínűbb, hogy a pontos javításra konvergál. Az Opus 0.5-ön kutató, aki lehetőségeket térképez fel. A Sonnet 0.2-ön sebész, aki egyetlen pontos vágást ejt.

A modell kaszkádnak gazdasági érve is van:

| Modell | Szerep | Költség (Kimenet/MTok) | Hőmérséklet | Miért Ez a Modell |
|---|---|---|---|---|
| **Opus** | Generálás | $25,00 | 0,5 | Kreatív, magas képesség újszerű appokhoz |
| **Sonnet** | Javítás | $25,00 | 0,2 | Pontos, gyors célzott javításokhoz |
| **Haiku** | Tanulás | $5,00 | 0,2 | Legolcsóbb képes modell kivonáshoz |

<ModelCascadeDemo />

Használd a legdrágább modellt, ahol a kreativitás számít. Használd a legolcsóbb képes modellt mechanikus feladatokhoz. Ez ugyanaz az elv, mint egy ház építése: építészt fogadsz a tervekhez és fizikai munkást a gipszkartonhoz. Mindkettő elengedhetetlen. Az egyiknek nem kell a másiknak lennie.

<Callout type="warning">
**Ötlet: Vizuális Hiba Debugger** -- *"Képzeld el, ha a fordító megmutatná egy időeltolásos felvételt arról, ahogy a hiba megszületik, diagnosztizálódik és javítódik."* A streaming esemény rendszer már minden fázist kiad: `GENERATING -> TRANSPILING -> FIXING -> LEARNING -> PUBLISHED`. Egy vizuális debugger lejátszhatná az ágens útját -- megmutatva a felhasználóknak, mi tört el és hogyan javítódott. Az átláthatatlan generálást átlátható debugolási munkamenetté alakítja. Minden `StreamEvent` típus vizuális ütemre képezhető le.
</Callout>

---

## A Memória -- Hogyan Fejlődik az Ágens

<BayesianConfidenceDemo />

Az ágens hurok egyedi hibákat javít. De a *memória rendszer* megakadályozza, hogy ezek a hibák megismétlődjenek az összes jövőbeli generálásban. Ez a különbség a debugolás és a tanulás közt.

Minden alkalommal, amikor hiba történik és javítódik (vagy nem), a Haiku kivon egy tanulási jegyzetet:

```typescript
export async function extractAndSaveNote(
  failingCode: string,
  error: string,
  fixedCode: string | null,
  path: string[],
): Promise<void> {
  const response = await callClaude({
    systemPrompt: NOTE_EXTRACTION_PROMPT,
    userPrompt:
      `Error: ${error}\n\nFailing code (excerpt):\n${failingCode.slice(0, 2000)}\n\nFixed code (excerpt):\n${fixedCode?.slice(0, 2000) || "N/A"}`,
    model: "haiku",
    maxTokens: 1024,
    temperature: 0.2,
  });
  // ... elemzés, deduplikálás, DB-ben tárolás
}
```

Minden jegyzet `CANDIDATE` státusszal és 0,5-ös konfidencia pontszámmal kezdi életét -- egy bizonyítatlan hipotézis. A Bayesi konfidencia rendszer aztán természetes szelekcióként működik:

```typescript
async function recalculateConfidence(noteId: string): Promise<void> {
  const note = await prisma.agentLearningNote.findUnique({
    where: { id: noteId },
  });

  const alpha = 1; // Priori sikerek
  const beta = 1;  // Priori kudarcok
  const score =
    (note.helpCount + alpha) / (note.helpCount + note.failCount + alpha + beta);

  // CANDIDATE -> ACTIVE előléptetés 3+ segítség és >0.6 konfidencia után
  if (status === "CANDIDATE" && note.helpCount >= 3 && score > 0.6) {
    status = "ACTIVE";
  }

  // DEPRECATED-ra fokozás, ha a konfidencia 0.3 alá esik
  if (score < 0.3 && note.helpCount + note.failCount >= 5) {
    status = "DEPRECATED";
  }
}
```

A formula -- `(segítségek + 1) / (segítségek + kudarcok + 2)` -- egy Beta-binomiális poszterior egyenletes priorral. Ez ugyanaz a matematika, ami az A/B tesztelés, a Thompson mintavétel és a többkarú rablók mögött áll. Nem kifinomult. Robusztus. A `+1` és `+2` tagok Laplace simítás -- megakadály nulla megfigyelés szélsőséges eseteket és mérsékelt priori bizonytalanságot fejeznek ki.

Az életciklus:

1. Hiba történik -> Haiku kivon egy jegyzetet -> `CANDIDATE`-ként tárolódik (0,5 konfidencia)
2. A jegyzet belekerül a jövőbeli promptokba az egyező slugokhoz
3. Ha a jegyzet segít (generálás sikerrel jár az alkalmazása után) -> **helpCount** nő -> konfidencia nő
4. 3+ segítség és >0,6 konfidencia után -> előléptetés **ACTIVE**-ra
5. Ha a jegyzet nem segít (generálások még mindig kudarcot vallanak) -> **failCount** nő -> konfidencia csökken
6. 0,3 alatti konfidencia 5+ megfigyelés után -> **DEPRECATED** (kihalt)

| Példa Jegyzet | Kiváltó | Lecke | Státusz |
|---|---|---|---|
| Three.js importok | `three.js scene setup` | `Import THREE from 'three' not '@three'` | ACTIVE (0,82) |
| Framer motion kilépés | `AnimatePresence children` | `Wrap exit animations in motion.div with key prop` | ACTIVE (0,71) |
| Recharts tooltip | `custom recharts tooltip` | `CustomTooltip must accept payload as array, not object` | CANDIDATE (0,55) |
| Régi tailwind szintaxis | `tailwind v3 classes` | `Use bg-red-500 not bg-red` | DEPRECATED (0,22) |

A minden prompthoz választott jegyzetek költségvetés-korlátosak. Nem darabszám, hanem tokenek szerint:

```typescript
function formatNotes(notes: LearningNote[]): string {
  const sorted = [...notes].sort((a, b) => b.confidenceScore - a.confidenceScore);

  const selected: LearningNote[] = [];
  let totalTokens = 0;
  for (const note of sorted) {
    const noteText = `- **${note.trigger}**: ${note.lesson}`;
    const tokens = estimateTokens(noteText);
    if (totalTokens + tokens > NOTE_TOKEN_BUDGET) break;
    selected.push(note);
    totalTokens += tokens;
  }
  // ...
}
```

A 800 tokenes költségvetés szándékosan szűk. Emlékezz a figyelem fizikájára: minden jegyzet token versenyez a kódgenerálási kontextussal a modell figyelméért. A magas konfidenciájú jegyzetek kiérdemlik a helyüket. Az alacsony konfidenciájú jegyzetek megmetsződnek. Természetes szelekció, softmax-on futva.

<Callout type="warning">
**Ötlet: Kereszt-bérlői Tanulás** -- *"Az ökológiában a monokultúrák törékenyek. Így az osztatlan tanulási tavak is."* Jelenleg minden tanulási jegyzet egy közös tóba kerül. De a játék-specifikus leckék ("mindig adj key propot az AnimatePresence gyermekeihez") hígíthatják a dashboard promptokat, ahol irrelevánsak -- pontosan ugyanaz a figyelmi hígítás probléma, de az adatrétegben. A jegyzetek kategória szerinti particionálása lehetővé tenné, hogy a játék ágens játék szakértelmet halmozzon fel a dashboard ágens keresztszennyezése nélkül.
</Callout>

<Callout type="warning">
**Ötlet: Tanulási Jegyzet Dashboard** -- *"Nem tudod kezelni, amit nem tudsz mérni."* Építs egy `/admin/agent-notes` oldalt, ami mutatja a konfidencia pályákat idő múltával, mely slugok profitáltak mely jegyzetekből, és mely jegyzetek közelítik a 0,3-as elavulás küszöböt. A megfigyelhető rendszerek jobbak a fekete dobozoknál. Az adatok már a Prisma-ban élnek -- csak UI kell nekik.
</Callout>

---

## Képesség Illesztés -- A Megfelelő Eszköz a Megfelelő Feladathoz

Amikor valaki lekéri a `/create/games/tetris`-t, a kulcsszó-kivonó elemzi az útvonalat és megtalálja a "games" és "tetris" szavakat. Ezek játék-specifikus képességeket indítanak: canvas-confetti ünnepléshez, howler.js játék audióhoz. Amikor a `/create/finance/dashboard` érkezik, más képességek aktiválódnak: recharts diagramokhoz, chart-ui shadcn/ui adat komponensekhez.

<Callout type="info">
**Fizikai analógia: impedancia illesztés.** Az elektronikában akkor kapsz maximális teljesítményátvitelt, amikor a forrás impedanciája illeszkedik a terhelés impedanciájához. A promptolásban akkor kapsz maximális generálási minőséget, amikor a prompt képesség-kontextusa illeszkedik a feladat követelményeihez. Egy játék prompt, amibe diagram könyvtár doksik vannak töltve, impedancia-eltérés -- az energia elpazarlódik rossz kontextus tolásával egy modellbe, aminek más kontextus kell. A képességek illesztése kérésekhez impedancia-illesztés a figyelemnek.
</Callout>

Az illesztés kulcsszóvezérelt, nem AI-vezérelt -- szándékosan egyszerű:

| Kategória | Képességek | Kiváltó Kulcsszavak |
|---|---|---|
| **3D** | Three.js, 3D Teljesítmény | three, 3d, globe, scene, planet, webgl |
| **Adat Viz** | Recharts, Chart UI | chart, dashboard, analytics, stock, metrics |
| **Játék** | Confetti, Játék Audió | game, puzzle, tetris, snake, arcade |
| **Űrlap** | React Hook Form, Űrlap Komponensek | form, survey, checkout, calculator |
| **DnD** | DnD Kit | kanban, drag, sortable, planner, todo |
| **Rajz** | Rough.js | draw, paint, sketch, whiteboard, doodle |
| **Tartalom** | React Markdown, Tartalom UI | blog, story, notes, recipe, portfolio |
| **Audió** | Howler.js, Web Audio | music, audio, drum, piano, synth |

Minden illeszkedő képesség a saját prompt szekcióját injektálja könyvtár-specifikus utasításokkal, import mintákkal és gyakori buktatókkal. A teljes prompt csak az illeszkedő képességekkel nő -- nem a teljes képesség katalógussal. Minimális elegendő kontextus. Maximális jelsűrűség.

<Callout type="warning">
**Ötlet: Tanult Képességek** -- *"Az evolúció nem csak a legalkalmasabbakat szelektálja. Új fajokat is generál."* Ha a Haiku folyamatosan olyan tanulási jegyzeteket von ki egy könyvtárról, ami nincs semmilyen képesség definícióban -- mondjuk, a `@tanstack/query` folyamatosan megjelenik adatlekéréses appokban -- az a minta jelölhető lenne teljes képesség definícióvá való előléptetésre. A képességek organikusan nőnének az ágens saját tapasztalatából, ahelyett, hogy kézzel lennének kódolva. Természetes szelekció alkalmazva magára a képesség katalógusra.
</Callout>

---

## A Proxy -- Fokozatos Leromlás

A produkciós architektúra három rétegű, mint egy villamos hálózat: elsődleges generátor, tartalék generátor, vészhelyzeti dízel.

```
Agent Proxy (localhost) -> Közvetlen Claude API -> Gemini Fallback
```

Az `isAgentAvailable()` függvény 3 másodperces egészségi ellenőrzést végez:

```typescript
export async function isAgentAvailable(): Promise<boolean> {
  if (!CREATE_AGENT_URL || !CREATE_AGENT_SECRET) return false;

  try {
    const controller = new AbortController();
    const timeout = setTimeout(() => controller.abort(), AGENT_TIMEOUT_MS);
    const res = await fetch(`${CREATE_AGENT_URL}/health`, {
      signal: controller.signal,
    });
    clearTimeout(timeout);
    return res.ok;
  } catch {
    return false;
  }
}
```

Ha a helyi ágens szerver fut (tanulási jegyzetek adatbázisával és teljes modell kaszkáddal), a forgalom oda irányul. Ha le van állítva, a rendszer visszaesik a folyamaton belüli Claude ágens hurokra. Ha a Claude API nem elérhető, a Gemini útvonalra degradálódik.

A felhasználó soha nem látja az átkapcsolást. Appot kap. A minőség fokozatosan romlik, ahelyett, hogy katasztrofálisan kudarcot vallana.

<Callout type="warning">
**Ötlet: Ágens Flotta** -- *"Miért legyen egy általánosító, amikor lehetnének specialisták?"* A proxy minta triviálissá teszi a kérések specializált ágens példányokhoz való irányítását. Egy "játék ágens" GPU szerveren játék-optimalizált tanulási jegyzetekkel. Egy "dashboard ágens" adatvizualizációs szakértelemmel. Minden példány domén-specifikus tudást halmoz fel, és a proxy az osztályozott kategória alapján irányít. Többágens koordináció infrastruktúra szinten.
</Callout>

---

## Hiba Intelligencia

Nem minden hiba egyenlően jószándékúan alkotott. Egy hiányzó import más probléma, mint egy típuseltérés, és mindkettő különbözik egy szintaktikai hibától. Az ágens nem csak "valami rosszul ment"-et lát -- diagnosztizál:

```typescript
export function parseTranspileError(rawError: string): StructuredError {
  const error: StructuredError = {
    type: "unknown",
    message: rawError.slice(0, 500),
  };

  // Hiányzó import / modul nem található
  if (/Cannot find module|Could not resolve|Module not found/i.test(rawError)) {
    error.type = "import";
    const moduleMatch = rawError.match(/['"]([^'"]+)['"]/);
    if (moduleMatch) error.library = moduleMatch[1];
  }
  // Típus hibák
  else if (/Type '.*' is not assignable|Property '.*' does not exist/i.test(rawError)) {
    error.type = "type";
  }
  // JSX/szintaxis hibák
  else if (/Unexpected token|Unterminated|Parse error/i.test(rawError)) {
    error.type = "transpile";
  }
  // Futásidejű hibák
  else if (/is not defined|Cannot read propert/i.test(rawError)) {
    error.type = "runtime";
  }
  // ... sorszám, komponens név, javaslat kivonás
  return error;
}
```

Négy hibatípus -- import, típus, transpile, runtime -- mindegyik más javítási stratégiát táplál. A strukturált hiba explicit kontextusként kerül injektálásra a javító promptba:

```
ERROR TYPE: import
LIBRARY: @react-three/fiber
LINE: 3
SUGGESTION: Did you mean 'three'?
```

Egy orvos nem azt mondja "valami nem stimmel." Diagnosztizál. A strukturált hibák diagnózis. A nyers hiba stringek "valami nem stimmel." A javító modell (Sonnet) drámásan jobban teljesít, amikor ismeri a hiba típusát, a specifikus könyvtárat és a sorszámot -- mert az kevesebb token nyomozómunka és több token tényleges javítás.

<Callout type="info">
**Ez visszacsatol a tanulásba.** A `categorizeErrorForNote` függvény a strukturált hibákat jegyzettípusokra képezi le. Import hibák `triggerType: "library"` jegyzeteket generálnak a specifikus csomaggal megcímkézve. Típus hibák `triggerType: "pattern"` jegyzeteket generálnak TypeScript címkével. A hiba struktúrája határozza meg, hogyan tárolódik, illeszkedik és választódik ki a jegyzet jövőbeli promptokhoz. Strukturált be, strukturált ki.
</Callout>

---

## A Meta-Építés

<RecursiveZoomDemo />

Íme a rész, ami széttörte az agyam.

A teljes önjavító ágenst a Claude Code terv módjával tervezték -- pontosan azzal a technikával, amit az ágens most belsőleg használ. Nem kézzel írtam a kódot, aztán elmélkedtem, miért működik. Használtam az eszközt, aztán tanulmányoztam, mit csinált az eszköz, aztán építettem egy rendszert, ami azt csinálja, amit az eszköz csinal.

A terv mód rákényszerítette a Claude-ot, hogy **feltérképezzen a cselekvés előtt.** Mielőtt egyetlen sor kódot megírtak volna, a modell beolvasta a meglévő kódbázist, megtalálta a content-generator mintákat, azonosította a codespace szolgáltatás API-t, feltérképezte a streaming esemény típusokat, és strukturált tervet készített. Az a tervfájl lett a kontextus-tervezett prompt a megvalósítási fázishoz.

Az 5 rétegű keretrendszer strukturálta a feltérképezést:
- **Identitás**: "Egy önjavító ágenst építesz a spike.land app létrehozójához"
- **Tudás**: Fájlútvonalak, meglévő minták, API szerződések a kódbázis-feltérképezésből
- **Példák**: A meglévő Gemini fallback mint referencia implementáció
- **Korlátozások**: "Ne törd meg a meglévő streaming szerződést. Tartsd meg a fallback-et."
- **Eszközök**: "Futtasd a `yarn test:coverage`-t a változtatások után. Ellenőrizd a transpilációt."

És a terv kimenete -- az ágens architektúra -- ugyanazt az 5 réteget használja a saját promptjaihoz. A `buildAgentSystemPrompt` függvény pontosan úgy strukturálja a kontextust, mint a terv, ami tervezte. Identitás réteg (AGENT_IDENTITY). Tudás réteg (tanulási jegyzetek). Példa réteg (képesség promptok). Korlátozás réteg (OUTPUT_SPEC). Eszköz réteg (transpiler + codespace API).

Rekurzív: kontextus-tervezést használtam egy rendszer építésre, ami kontextus-tervezést csinál.

<Callout type="success">
**A rekurzív felismerés:** A tervfájl egy prompt volt. A prompt egy rendszert épített, ami promptokat épít. A tanulási jegyzetek természetes szelekció által finomított promptok. Minden szinten -- embertől Claude Code-ig, Claude Code-tól ágensig, ágenstől modellig -- ugyanaz a minta ismétlődik: kontextus összeállítása, figyelem korlátozása, eredmények mérése, tanulás. Kontextus-tervezés végig lefelé.
</Callout>

<AudioPlayer src="/audio/physics-of-attention.m4a" title="Mély Merülés: A Figyelem Fizikája (kísérő audió a 2. cikkből)" />

---

## Amit Mértünk

A `recordGenerationAttempt` függvény minden generálást teljes megfigyelhetőséggel követ: slug, siker/kudarc, iterációs szám, időtartam, alkalmazott jegyzetek, előfordult hibák, használt modell, token számlálók és cache találatok.

| Metrika | Előtte (Gemini Flash) | Utána (Ágens Hurok) |
|---|---|---|
| **Első próbás sikerarány** | ~40% | ~65% |
| **Siker újrapróbák után** | ~55% (1 újrapróba) | ~85% (akár 3 iteráció) |
| **Átlag iteráció a sikerig** | 1,6 | 1,4 |
| **Költség generációnként** | ~$0,005 | ~$0,08-0,12 |
| **Medián késleltetés** | 8 mp | 15-25 mp |
| **Alkalmazott tanulási jegyzetek** | 0 | 3-7 generációnként |

<Callout type="info">
**A kompromisszum valós.** Az ágens lassabb és kérésenként 15-20x drágább. De gondolj a gazdaságosságra a felhasználó szempontjából: egy $0,10-os generálás, ami működik, végtelenül értékesebb, mint egy $0,005-os generálás, ami törött appot hoz létre. Egy sikertelen generálás költsége nem $0,005 -- hanem a felhasználó ideje, frusztrációja és a visszatérés valószínűsége. A minőség kamatozik. A kudarcok nem.
</Callout>

A metrikák valami váratlant is mutatnak: a tanulási jegyzeteknek csökkenő hozamuk van. Az első 3-5 magas konfidenciájú jegyzet jelentősen javítja a sikerarányt. Ezután a figyelmi költségvetés versengni kezd. Több jegyzet nem jelent jobb eredményeket -- ugyanaz a fizika, ami motiválja a jegyzetek 800 tokenes költségvetését.

<Callout type="warning">
**Ötlet: A/B Tesztelés** -- *"A tudománynak kontrollcsoportra van szüksége."* A fallback architektúra triviálissá teszi az A/B tesztelést. Véletlenszerűen irányítsd a kérések 50%-át a teljes ágens hurkon és 50%-át a Gemini fallback-en keresztül. Kövesd nyomon a sikerarányt, felhasználói visszatérési arányt és a sikeres generációnkénti költséget. Hagyd, hogy az adatok döntsenek, hogy az összetettség és a költség indokolt-e. A proxy már kezeli az irányítást -- csak egy érmefeldobás kell.
</Callout>

---

## Kezdj El Építeni

Három tanulság, a fizikára alapozva:

**1. Őrizd meg a figyelmi költségvetésedet.** A promptodban minden token versenyez a modell véges figyelméért. Mielőtt kontextust adsz hozzá, kérdezd meg: "Megváltoztatná-e ennek eltávolítása a kimenetet?" Ha nem, távolítsd el. Az 5 rétegű verem nem arról szól, hogy több kontextust adj hozzá -- hanem a *megfelelő* kontextust és semmi mást. Megmaradás, nem felhalmozás.

**2. Építs visszacsatolási hurkokat, ne nagyobb promptokat.** Az ágens nem azért sikeres, mert jobb a promptja, mint a Gemini-é. Azért sikeres, mert kudarcot tud vallani, diagnosztizálni, javítani és tanulni. Egy közepes prompt visszacsatolási hurokkal felülmúl egy briliáns promptot emlékezet nélkül. Az evolúció verte az intelligens tervezést -- elég iteráció esetén.

**3. Illeszd az eszközöket a feladathoz.** Opus az alkotáshoz, Sonnet a javításhoz, Haiku a tanuláshoz. Magas hőmérséklet a feltérképezéshez, alacsony hőmérséklet a precizitáshoz. Drága modellek, ahol a kreativitás számít, olcsó modellek, ahol a kivonás számít. A megfelelő eszköz a megfelelő költségen a megfelelő feladathoz -- impedancia-illesztés végig lefelé.

<CTAButton href="/create">Próbáld Ki az App Kreátort</CTAButton>

---

<div className="bg-gradient-to-r from-blue-600/20 to-purple-600/20 border border-blue-500/30 rounded-lg p-6 mt-8">
  <h3 className="text-lg font-semibold mb-3 text-slate-200">A Kontextus-tervezés Trilógia</h3>
  <p className="text-slate-300 mb-4">
    Ez a cikk egy háromrészes sorozat utolsó darabja. Kezdd az elmélettel, értsd meg a mechanizmust, aztán lásd alkalmazva egy valós termékre.
  </p>
  <div className="flex flex-wrap gap-3">
    <a
      href="/blog/context-engineering-your-zero-shot-prompt"
      className="inline-flex items-center px-4 py-2 bg-blue-600 hover:bg-blue-700 text-white font-medium rounded-lg transition-colors"
    >
      1. Rész: Az 5 Rétegű Keretrendszer
    </a>
    <a
      href="/blog/how-claude-code-engineers-context"
      className="inline-flex items-center px-4 py-2 bg-blue-600 hover:bg-blue-700 text-white font-medium rounded-lg transition-colors"
    >
      2. Rész: A Transformer Belsejében
    </a>
    <a
      href="https://github.com/zerdos/spike-land-nextjs"
      className="inline-flex items-center px-4 py-2 bg-slate-700 hover:bg-slate-600 text-white font-medium rounded-lg transition-colors"
    >
      Fedezd Fel a Forráskódot
    </a>
  </div>
</div>

---

*A legjobb AI nem az, amelyik a legjobban próbálkozik. Hanem az, amelyik emlékszik arra, mi ment rosszul. A vibe coding entrópia -- energia irány nélkül. A kontextus-tervezés a második törvény: a világegyetem a rend felé tart, de csak ha elvégzed a munkát.*
