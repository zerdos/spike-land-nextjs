---
title: "La pyramide des tests est à l'envers"
slug: "the-testing-pyramid-is-upside-down"
description: "Et si la pire partie de votre suite de tests — les tests E2E lents et instables — pouvait tourner à la vitesse des tests unitaires ? Les MCP pourraient être la réponse que personne n'attendait."
date: "2026-02-13"
author: "Zoltan Erdos"
category: "Expérience développeur"
tags: ["testing", "mcp", "unit-testing", "e2e", "architecture", "agents"]
featured: true
language: "fr"
---

*Dédié à la mémoire de László Merklik (1975-2018), qui nous a quittés bien trop tôt. Il était au début de la quarantaine quand le cancer l'a emporté. En tant que co-fondateur et CPO d'Emarsys — plus tard acquis par SAP — il a bâti l'une des cultures d'ingénierie les plus respectées de Hongrie. Il a même donné une conférence intitulée "Better Quality Without Testers", qui ressemble à un ancêtre direct des idées de cet article.*

*László est la personne qui m'a fait m'intéresser au code. Pas juste le faire — s'y intéresser. Il m'a appris qu'il existe une relation spéciale entre un test unitaire et le code qu'il teste : quand les deux sont écrits correctement, l'un spécifie l'autre. Le test vous dit ce que le code devrait faire. Le code vous dit ce que le test devrait vérifier. Ce sont deux vues de la même vérité.*

*C'était le genre de développeur qui rendait meilleur tous ceux qui l'entouraient. Le genre qui restait après les conférences pour aider un junior à corriger son build. Le genre qui croyait que bien écrire du logiciel est une forme de respect — envers vos coéquipiers, envers vos utilisateurs, envers vous-même. Cet article parle de faire avancer le métier. C'était son truc aussi.*

---

## La conférence

Il y a environ quinze ans, je suis allé à une conférence de développeurs à Budapest. Le sujet était Jasmine — qui tournait dans le navigateur, puisque Node.js lui-même n'était pas encore largement adopté. C'était avant que Jest n'ait conquis le monde, avant que le testing ne soit acquis sur chaque projet. Le testing était encore quelque chose pour lequel il fallait argumenter.

Le présentateur était jeune. Énergie nerveuse. Il avait clairement été converti récemment — on pouvait le voir dans ses yeux. Il nous a guidés à travers comment quelques dizaines de tests unitaires avaient attrapé une régression qui aurait été livrée en production. Il a montré comment le mocking fonctionnait. Il a montré la rapidité de la boucle de feedback. Il vibrait presque.

Puis quelqu'un dans l'audience a levé la main.

"Es hogy teszteljük le az UI-t ?" a demandé la personne — *"Et comment on teste l'UI ?"*

Le présentateur a marqué une pause. Puis il a haussé les épaules.

"Az UI-t? Azt teszteljék a hülyék!" — *"L'UI ? Que les idiots la testent !"*

Quelques personnes ont ri. La plupart ont hoché la tête. Ça semblait raisonnable à l'époque. Les tests unitaires couvraient la logique métier. L'UI n'était que du HTML et du CSS. On la regarde, ça a l'air bien ou pas. Qu'y a-t-il à automatiser ?

Cette réponse est restée gravée dans ma mémoire longtemps. Pas parce qu'elle était fausse. Parce qu'elle était presque juste — et l'écart entre presque juste et vraiment juste allait coûter à notre industrie une décennie de souffrances.

---

## Ce qui s'est passé ensuite

Nous avons commencé à tester l'UI. Bien sûr que oui.

D'abord est venu Selenium. Puis Protractor. Puis Cypress. Puis Playwright. Chacun meilleur que le précédent. Chacun promettant de finalement rendre le testing en navigateur fiable.

Et ils se sont améliorés. Playwright en particulier est un outil véritablement excellent. Mais le problème fondamental n'a jamais disparu : vous contrôlez un vrai navigateur, rendez un vrai DOM, attendez de vraies requêtes réseau, et espérez que le timing fonctionne. Vous testez à travers la couche la plus épaisse et la plus imprévisible de toute votre stack.

Ces tests sont devenus la pire partie de chaque suite de tests sur laquelle j'ai travaillé.

Ils sont lents. Une suite de tests unitaires rapide tourne en secondes. Une suite E2E complète tourne en minutes — parfois des dizaines de minutes. Sur le CI, avec la parallélisation et les réessais, vous regardez des temps de pipeline qui font que les développeurs changent de contexte vers autre chose pendant qu'ils attendent.

Ils sont instables. Pas parce que les outils sont mauvais, mais parce que les navigateurs sont des machines à états complexes. Un test qui passe localement échoue sur le CI parce que l'animation a pris 50ms de plus. Un test qui tournait bien hier échoue aujourd'hui parce qu'un script tiers s'est chargé plus lentement. Vous ajoutez `waitForSelector`. Vous ajoutez `waitForTimeout`. Vous ajoutez de la logique de réessai. Vous ne testez plus votre application — vous testez votre capacité à vous synchroniser avec le chaos.

Ils sont fragiles. Changez une classe CSS ? Les tests cassent. Déplacez un bouton de la barre latérale gauche à la navigation du haut ? Les tests cassent. Refactorez un composant qui se comporte de manière identique mais se rend différemment ? Les tests cassent. Les tests sont couplés à l'implémentation exactement de la façon dont nous disons aux développeurs juniors de ne pas écrire les tests unitaires.

C'est la pyramide des tests. Les tests unitaires à la base : rapides, peu coûteux, nombreux. Les tests d'intégration au milieu : vitesse modérée, coût modéré, nombre modéré. Les tests E2E au sommet : lents, chers, peu nombreux.

Tout le monde sait que le sommet de la pyramide est douloureux. Nous l'avons accepté comme le coût de faire des affaires. Il faut *quelques* tests E2E parce que c'est le seul moyen de vérifier le flux utilisateur complet. Les tests d'API ne suffisent pas — ils testent des endpoints, pas les flux de logique métier qui enchaînent ces endpoints en quelque chose qu'un utilisateur fait réellement.

Du moins c'est ce que nous pensions.

---

## L'insight

Voici le truc concernant les tests E2E dont personne ne parle assez clairement : la plupart d'entre eux ne testent pas vraiment le navigateur. Ils testent la logique métier *à travers* le navigateur.

Pensez à ce qu'un test E2E typique vérifie réellement. "L'utilisateur se connecte, navigue vers les paramètres, change son email, confirme le changement, voit l'email mis à jour sur la page de profil." Que testez-vous vraiment ici ? Vous testez que le flux de changement d'email fonctionne. La connexion, la navigation, la soumission du formulaire, la confirmation, la mise à jour d'état — tout ça c'est de la logique métier. Le navigateur n'est que le mécanisme de livraison.

Ce n'est pas une observation nouvelle. L'architecture hexagonale d'Alistair Cockburn (2005) argumentait que les applications devraient être également pilotables par les utilisateurs, les programmes et les scripts de test. Martin Fowler a nommé le pattern "subcutaneous testing" — tester juste sous l'UI. La Clean Architecture de Robert C. Martin insistait sur le fait que les règles métier doivent être testables sans aucune UI. L'insight était toujours là. Ce qui manquait était une interface standardisée qui le rende pratique à grande échelle.

MCP — Model Context Protocol — est cette interface. C'est un standard pour exposer les capacités de votre application comme des outils structurés. Du texte en entrée, du texte en sortie. Un agent envoie une requête décrivant ce qu'il veut faire, votre serveur MCP exécute l'action et retourne le résultat. Pas de navigateur. Pas de DOM. Pas de sélecteurs CSS. Pas de problèmes de timing. Si vous écrivez vos user stories comme des outils MCP, vous avez créé un contrat testable pour votre logique métier.

Laissez-moi vous montrer ce que je veux dire.

Disons que vous avez une user story : "Un utilisateur peut mettre à jour son adresse email." Dans le monde E2E, le test ressemble à quelque chose comme ça :

```typescript
// Cypress E2E test
describe('Email update flow', () => {
  it('should allow user to change their email', () => {
    cy.login('test@example.com', 'password123');
    cy.visit('/settings');
    cy.get('[data-testid="email-input"]').clear().type('new@example.com');
    cy.get('[data-testid="save-button"]').click();
    cy.get('[data-testid="confirm-dialog"]').should('be.visible');
    cy.get('[data-testid="confirm-button"]').click();
    cy.get('[data-testid="success-toast"]').should('contain', 'Email updated');
    cy.visit('/profile');
    cy.get('[data-testid="user-email"]').should('contain', 'new@example.com');
  });
});
```

Ce test prend 5-15 secondes à tourner. Il dépend de sélecteurs CSS, de la structure du DOM, du timing des animations et de la latence réseau. Changez le dialogue de confirmation en modal ? Le test casse. Déplacez le message de succès d'un toast vers une alerte inline ? Le test casse.

Maintenant voici la même logique métier exposée comme un outil MCP :

```typescript
// MCP tool definition
const updateEmailTool = {
  name: 'update_user_email',
  description: 'Update the authenticated user\'s email address',
  inputSchema: {
    type: 'object',
    properties: {
      newEmail: { type: 'string', format: 'email' },
      confirmChange: { type: 'boolean' },
    },
    required: ['newEmail', 'confirmChange'],
  },
  handler: async ({ newEmail, confirmChange }, context) => {
    const user = await context.getAuthenticatedUser();
    if (!user) return { error: 'Not authenticated' };

    if (!confirmChange) {
      return {
        status: 'confirmation_required',
        message: `Confirm email change from ${user.email} to ${newEmail}?`,
      };
    }

    await context.userService.updateEmail(user.id, newEmail);
    return {
      status: 'success',
      message: `Email updated to ${newEmail}`,
      updatedEmail: newEmail,
    };
  },
};
```

Et le test unitaire :

```typescript
// Unit test for the MCP tool
describe('update_user_email', () => {
  it('should update email when confirmed', async () => {
    const context = createMockContext({
      user: { id: '1', email: 'old@example.com' },
    });

    const result = await updateEmailTool.handler(
      { newEmail: 'new@example.com', confirmChange: true },
      context,
    );

    expect(result.status).toBe('success');
    expect(result.updatedEmail).toBe('new@example.com');
    expect(context.userService.updateEmail).toHaveBeenCalledWith(
      '1',
      'new@example.com',
    );
  });

  it('should require confirmation before updating', async () => {
    const context = createMockContext({
      user: { id: '1', email: 'old@example.com' },
    });

    const result = await updateEmailTool.handler(
      { newEmail: 'new@example.com', confirmChange: false },
      context,
    );

    expect(result.status).toBe('confirmation_required');
    expect(context.userService.updateEmail).not.toHaveBeenCalled();
  });

  it('should reject unauthenticated requests', async () => {
    const context = createMockContext({ user: null });

    const result = await updateEmailTool.handler(
      { newEmail: 'new@example.com', confirmChange: true },
      context,
    );

    expect(result.error).toBe('Not authenticated');
  });
});
```

Ce test tourne en millisecondes. Il ne dépend d'aucune structure DOM. Il se moque de ce à quoi ressemble l'UI. Il teste exactement la même logique métier — le flux de mise à jour d'email avec confirmation — mais à la vitesse des tests unitaires, avec la fiabilité des tests unitaires.

Vous n'avez perdu aucune couverture. Vous avez perdu le navigateur.

---

## L'argument architectural

Ce n'est pas juste une astuce de testing. C'est un changement architectural.

Quand vous exposez vos user stories comme des outils MCP, vous créez une chaîne :

**User stories → outils MCP → logique métier testable unitairement**

La même spécification sert trois objectifs simultanément :

1. **Documentation utilisateur.** Les descriptions des outils MCP *sont* votre documentation de fonctionnalités. "Mettre à jour l'adresse email de l'utilisateur authentifié" — c'est la spécification, écrite en langage clair, vivant dans le code.

2. **Interface pour agents.** Tout agent IA qui se connecte via MCP peut maintenant exécuter vos user stories. Votre application est prête pour les agents non pas parce que vous avez boulonné une fonctionnalité IA, mais parce que votre logique métier est accessible à travers une interface texte structurée.

3. **Contrat de test.** Le schéma d'entrée définit ce que l'outil accepte. Le handler définit le comportement attendu. La réponse définit la sortie attendue. C'est un contrat. Vous pouvez le tester de la même façon que vous testez n'importe quelle fonction — parce que c'*est* une fonction.

Vous pourriez obtenir une testabilité similaire avec une simple couche de services — une fonction `updateUserEmail()` bien structurée est tout aussi testable qu'un handler MCP. Mais une fonction de service sert un seul maître : votre application. Un outil MCP en sert trois. Le même artefact est votre contrat de test, votre interface pour agents et votre documentation de fonctionnalité. Vous l'écrivez une fois ; il vous rapporte de trois façons. Ce n'est pas une astuce de testing. C'est un multiplicateur de force architectural.

C'est l'insight clé qui m'a pris des années à voir : la raison pour laquelle les tests E2E sont douloureux n'est pas que l'automatisation de navigateur est difficile (bien qu'elle le soit). C'est que nous étions forcés de passer par le navigateur parce qu'il n'y avait pas d'autre moyen d'exercer les flux utilisateurs complets. Le navigateur était la seule interface qui connectait tous les morceaux.

Les MCP vous donnent une seconde interface. Une interface textuelle avec des schémas auto-descriptifs que les machines peuvent découvrir, invoquer et vérifier. Une qui connecte les mêmes morceaux mais sans la couche de rendu, sans les problèmes de timing, sans les sélecteurs CSS.

---

## Le troisième joueur

László m'a appris la dualité : un test unitaire et son code, quand ils sont écrits correctement, se spécifient l'un l'autre. Deux joueurs, une vérité.

Mais je pense qu'il y a un troisième joueur : le nom.

Considérez l'outil MCP de tout à l'heure : `update_user_email`. Ce nom n'est pas juste un label. C'est une contrainte. Il vous dit ce que l'outil doit faire et ce qu'il ne doit pas faire. Il n'envoie pas de notifications. Il ne met pas à jour le mot de passe. Il met à jour l'email de l'utilisateur.

Un bon nommage a toujours compté. Une fonction bien nommée contraint ce qu'un développeur écrit. Mais un nom d'outil MCP contraint ce qu'une *machine* peut découvrir, invoquer et tester. Un agent IA qui parcourt votre serveur MCP ne lit pas votre code source — il lit les noms des outils, les descriptions et les schémas. Si `update_user_email` est correctement nommé, un agent sait pourquoi l'appeler sans lire l'implémentation. Le nom devient un contrat découvrable.

Test. Code. Nom. Trois joueurs, une vérité. Le nom, le schéma d'entrée et le handler forment un triangle où chaque sommet contraint les deux autres. Nous avions les deux premiers depuis des décennies. MCP a formalisé le troisième en quelque chose que les machines peuvent raisonner — et il s'avère que, quand vous donnez au nom assez de structure pour être lisible par une machine, il devient testable par une machine aussi.

---

## Étapes pratiques

Si vous fixez une suite E2E instable en ce moment, voici comment commencer.

**Étape 1 : Trouvez vos tests E2E les plus douloureux.** Vous savez lesquels. Ceux que vous relancez trois fois avant qu'ils passent. Ceux qui ont des commentaires `// TODO: comprendre pourquoi c'est instable`. Ceux qui prennent 30 secondes chacun.

**Étape 2 : Demandez-vous quelle logique métier ils vérifient réellement.** Enlevez les clics et les attentes et les sélecteurs. Que teste réellement le test ? "L'utilisateur peut annuler son abonnement." "L'admin peut bannir un utilisateur." "Le flux de paiement gère les cartes refusées." C'est la logique métier.

**Étape 3 : Exposez cette logique comme des outils MCP.** Écrivez un outil MCP pour chaque flux métier. Définissez le schéma d'entrée, implémentez le handler en utilisant vos services existants, retournez des résultats structurés. Vous ne réécrivez rien — vous enveloppez votre logique métier existante dans une interface structurée.

**Étape 4 : Écrivez des tests unitaires pour les outils MCP.** Moquez les dépendances. Testez le parcours nominal. Testez les cas d'erreur. Testez les cas limites. Ces tests tourneront en millisecondes et ne seront jamais instables.

**Étape 5 : Regardez votre suite E2E rétrécir.** Vous aurez encore besoin de quelques tests E2E — pour les régressions visuelles, pour les comportements spécifiques au navigateur, pour le câblage d'intégration qui ne se révèle que dans un vrai environnement (CORS, middleware d'authentification, hydratation). Mais le nombre va chuter dramatiquement. Ceux que vous gardez seront plus simples et plus stables parce qu'ils ne portent plus le poids de la vérification de la logique métier.

Vous ne remplacez pas les tests E2E. Vous en sortez la logique métier. Ce qui reste est une fine couche de tests de fumée visuels — ce que les tests E2E auraient dû être depuis le début.

---

## Le dividende CI

Une fois que votre logique métier vit dans des outils MCP, étroitement couplée à votre frontend via TypeScript, quelque chose de remarquable arrive à votre pipeline CI.

Lancez ça :

```bash
yarn vitest run --changed main
```

Vitest sait quels fichiers ont changé depuis `main`. Il sait quels tests importent ces fichiers. Il n'exécute que ces tests. Un changement dans `update_user_email` lance les tests email, pas la suite entière. Ça prend des secondes, pas des minutes.

Mais le vrai truc est ce qui vient après.

Votre CI a des logs de couverture. Il a l'historique git. Il sait quels outils MCP ont changé, quels tests unitaires les couvrent, et quels scénarios E2E exercent ces flux. Un agent réviseur IA peut lire ce graphe et prendre une décision : quels tests E2E doivent réellement tourner ?

Mis à jour la description dans un fichier de fixture de test ? Pas de tests E2E nécessaires. Changé la logique de validation d'email dans un outil MCP ? Lancer les scénarios E2E liés à l'email, sauter le reste. Refactoré un utilitaire partagé ? L'agent trace le graphe de dépendances et lance exactement les tests affectés — ni plus, ni moins.

C'est de la revue incrémentale, alimentée par le même couplage qui a rendu vos tests unitaires rapides. Les noms des outils MCP donnent à l'agent assez de contexte sémantique pour raisonner sur le rayon d'impact. `update_user_email` a changé ? L'agent sait qu'il faut lancer les tests E2E d'email. `list_user_notifications` inchangé ? Les sauter.

Les économies se composent. Sur une grande base de code, une PR typique touche une fraction de la logique métier. Lancer la suite E2E complète pour chaque PR est comme reconstruire toute la maison parce que vous avez changé une poignée de porte. Avec une logique métier structurée en MCP et un réviseur IA, votre CI n'exécute que ce qui compte.

Moins de calcul. Feedback plus rapide. Moins d'échecs instables de tests qui n'avaient rien à voir avec votre changement. La pyramide ne se contente pas de se remodeler — elle devient intelligente.

---

## La pyramide, reconsidérée

La pyramide des tests a toujours été un compromis. Nous avons mis les tests E2E au sommet non pas parce que nous voulions qu'ils soient lents et peu nombreux, mais parce que c'était la contrainte. La vérification complète des flux utilisateurs nécessitait un navigateur. Les navigateurs sont lents. Donc les tests de flux utilisateur complets sont lents. Donc en écrire moins.

Les MCP cassent cette contrainte.

Si votre logique métier est accessible via une interface texte, la vérification complète des flux utilisateurs ne nécessite pas de navigateur. Elle nécessite un appel de fonction. Les appels de fonction sont rapides. Donc les tests de flux utilisateur complets sont rapides. Donc en écrire autant que vous voulez.

La pyramide ne se retourne pas. Elle se remodèle. La couche supérieure douloureuse — la couche E2E — devient fine. La logique métier qui la gonflait descend dans la couche de tests unitaires. Pas parce que vous avez trouvé une façon astucieuse de moquer le navigateur, mais parce que vous avez supprimé le besoin du navigateur entièrement.

Les tests E2E restants font ce qu'ils auraient toujours dû faire : vérifier que la page se rend, que le câblage d'intégration tient, que le design visuel est correct. "Que les idiots testent ça" — sauf que maintenant les "idiots" sont Playwright exécutant une poignée de vérifications ciblées, pas une centaine de simulations lentes de logique métier.

---

## Retour aux sources

Je repense parfois à cette conférence. Le jeune présentateur, vibrant d'excitation pour les tests unitaires. La personne dans l'audience demandant comment tester l'UI. La réponse dédaigneuse.

"Az UI-t? Azt teszteljék a hülyék!" — *"L'UI ? Que les idiots la testent !"*

Il n'avait pas tort. Il était en avance.

La vraie réponse à la question du test UI n'a jamais été "automatisez le navigateur." La vraie réponse était : rendez la logique métier accessible sans navigateur. Nous n'avions tout simplement pas encore l'interface pour ça.

Maintenant nous l'avons.

László aurait adoré ça. Pas la technologie en elle-même — il n'était jamais du genre à s'enthousiasmer pour un protocole ou une spécification. Il aurait adoré ce que ça signifie pour le métier. Moins de temps à combattre des tests instables. Plus de temps à construire des choses qui comptent. Plus de temps à aider le développeur junior après les conférences.

C'est ça, faire avancer le métier. Pas des outils tape-à-l'oeil. Des boucles de feedback plus silencieuses. Moins de friction entre l'intention et la vérification. Le genre ennuyeux de progrès qui rend tout le reste possible.

Je pense à lui chaque fois que je supprime un test instable. Je pense qu'il approuverait.
